{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Trading Strategy\n",
    "Letting Tweet Sentiment determine buy, sell, or holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "Getting prices and Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twint Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweets(search_term, until, limit=20):\n",
    "    \"\"\"\n",
    "    Configures Twint and returns a dataframe of tweets for a specific day.\n",
    "    \"\"\"\n",
    "    # Configuring Twint for search\n",
    "    c = twint.Config()\n",
    "\n",
    "    # The limit of tweets to retrieve\n",
    "    c.Limit = limit\n",
    "\n",
    "    # Search term\n",
    "    c.Search = search_term\n",
    "\n",
    "    # Removing retweets\n",
    "    c.Filter_retweets = True\n",
    "    \n",
    "    # Popular tweets\n",
    "    c.Popular_tweets = True\n",
    "\n",
    "    # Lowercasing tweets\n",
    "    c.Lowercase = True\n",
    "\n",
    "    # English only\n",
    "    c.Lang = 'en'\n",
    "\n",
    "    # Tweets until a specified date\n",
    "    c.Until = until + \" 00:00:00\"\n",
    "    \n",
    "    # Making the results pandas friendly\n",
    "    c.Pandas = True\n",
    "    \n",
    "    # Stopping print in terminal\n",
    "    c.Hide_output = True\n",
    "\n",
    "    # Searching\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    # Assigning the DF\n",
    "    df = twint.storage.panda.Tweets_df\n",
    "    \n",
    "    # Returning an empty DF if no tweets were found\n",
    "    if len(df)<=0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Formatting the date\n",
    "    df['date'] = df['date'].apply(lambda x: x.split(\" \")[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twint over Time Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetByDay(start, end, df, search, limit=20):\n",
    "    \"\"\"\n",
    "    Runs the twint query everyday between the given dates and returns\n",
    "    the total dataframe.\n",
    "    \"\"\"\n",
    "    # Finishing the recursive loop\n",
    "    if start==end:\n",
    "        # Removing any potential duplicates\n",
    "        df = df.drop_duplicates(subset=\"id\")\n",
    "        print(len(df))\n",
    "        return df\n",
    "    \n",
    "    # Appending the new set of tweets for the day\n",
    "    tweet_df = getTweets(search, end, limit)\n",
    "    \n",
    "    # Running the query a few more times in case twint missed some tweets\n",
    "    run = 0 \n",
    "    \n",
    "    while len(tweet_df)==0 or run<=2:\n",
    "        # Running query again\n",
    "        tweet_df = getTweets(search, end, limit)\n",
    "        \n",
    "        # Counting how many times it ran\n",
    "        run += 1\n",
    "    \n",
    "    # Adding the new tweets\n",
    "    df = df.append(tweet_df, ignore_index=True)\n",
    "    \n",
    "    # Updating the new end date\n",
    "    new_end = (datetime.strptime(end, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Printing scraping status\n",
    "    print(f\"\\t{len(df)} Total Tweets collected as of {new_end}\\t\")\n",
    "    \n",
    "    # Running the function again\n",
    "    return tweetByDay(start, new_end, df, search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(df, measurement=\"compound\"):\n",
    "    \"\"\"\n",
    "    Given a DF of tweets, analyzes the tweets and returns a new DF\n",
    "    of sentiment scores based on the given measurement.\n",
    "    Accepted sentiment measurements: [\"pos\", \"neg\", \"neu\", \"compound\"]\n",
    "    \"\"\"\n",
    "\n",
    "    # Sentiment Analyzer\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Getting the sentiment score\n",
    "    df['sentiment'] = df['tweet'].apply(lambda x: sia.polarity_scores(x)[measurement])\n",
    "\n",
    "    # Creating a DF with the average sentiment score each day\n",
    "    sent_df = df.groupby('date')['sentiment'].mean().reset_index()\n",
    "    \n",
    "    # Converting the dates to datetime\n",
    "    sent_df['date'] = sent_df['date'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "    \n",
    "    return sent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStockPrices(ticker, start, end):\n",
    "    \"\"\"\n",
    "    Gets the historical daily prices between two dates. Scaling the prices based on a\n",
    "    given sentiment dataframe.\n",
    "    \"\"\"\n",
    "    # Setting the stock\n",
    "    stock = yf.Ticker(ticker)\n",
    "\n",
    "    # Getting historical prices\n",
    "    stock_df = stock.history(start=end, end=start, interval=\"1d\")[['Close']]\n",
    "        \n",
    "    # Getting the daily percent returns\n",
    "    stock_df = stock_df.pct_change(1).dropna()\n",
    "    \n",
    "    # Some reformatting\n",
    "    stock_df = stock_df.reset_index().rename(\n",
    "        columns={\n",
    "            \"Date\": \"date\",\n",
    "            \"Close\": \"returns\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return stock_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment and Price Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAndPrice(ticker, start, end, numtweets=20):\n",
    "    \"\"\"\n",
    "    Visually compares sentiment with the closing price of a given stock ticker.\n",
    "    \"\"\"\n",
    "    # Creating a DF that contains daily tweets between two dates\n",
    "    df = tweetByDay(start, end, pd.DataFrame(), search=\"$\"+ticker, limit=numtweets)\n",
    "        \n",
    "    # Analyzing the sentiment of each tweet\n",
    "    sent_df = getSentiment(\n",
    "        df, \n",
    "        measurement='compound'\n",
    "    )\n",
    "    \n",
    "    # Getting stock price history\n",
    "    stock_df = getStockPrices(\n",
    "        ticker, \n",
    "        start, \n",
    "        end\n",
    "    )\n",
    "    \n",
    "    # Merging the two DF\n",
    "    comb_df = sent_df.merge(stock_df, how='outer', sort=True)\n",
    "    \n",
    "    # Shifting the sentiment scores 1 day to compensate for lookahead bias\n",
    "    comb_df['sentiment'] = comb_df['sentiment'].shift(1)\n",
    "    \n",
    "    # Scaling the returns\n",
    "#     scaler = MinMaxScaler(\n",
    "#         feature_range=(\n",
    "#             comb_df['sentiment'].min(),\n",
    "#             comb_df['sentiment'].max()\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     comb_df[['returns']] = scaler.fit_transform(comb_df[['returns']])\n",
    "        \n",
    "    # How often sentiment matched return\n",
    "\n",
    "    # Dropping NAs so they are not compared\n",
    "    drop_df = comb_df.dropna()\n",
    "\n",
    "    # Comparing matches\n",
    "    match = (drop_df['sentiment'].apply(lambda x: x>0)==drop_df['returns'].apply(lambda x: x>0))\n",
    "\n",
    "    # Counting instances where they match\n",
    "    match = match.value_counts().rename({False: \"Didn't predict return\",\n",
    "                                         True: \"Successfully predicted return\"}).to_frame()\n",
    "    \n",
    "    # Visualizing matches in sentiment and return\n",
    "    fig = px.bar(\n",
    "        match,\n",
    "        x=0,\n",
    "        y=match.index,\n",
    "        color=match.index,\n",
    "        title=\"Instances when Sentiment predicts Return\",\n",
    "        labels={\"index\": \"Prediction\",\n",
    "                \"0\": \"Count\"}\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "        \n",
    "    # Visualizing the sentiment and price\n",
    "    fig = px.bar(\n",
    "        comb_df,\n",
    "        x='date',\n",
    "        y=['returns', 'sentiment'],\n",
    "        barmode='group',\n",
    "        title=f\"Returns & Sentiment over Time for {ticker}\"\n",
    "    )\n",
    "    \n",
    "    return fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
